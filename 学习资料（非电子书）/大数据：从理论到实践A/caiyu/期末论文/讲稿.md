# GAN

大家好，我是胡才郁，今天我给大家介绍一下我所做的工作。

我做的工作是根据动漫头像数据集，生成相似的动漫头像。



## 数据集来源

首先第一部分，是我的数据来源。我采用的数据集来自于Kaggle中的项目，本数据集共由71314张动漫头像组成，并且图像尺寸为96*96。该数据集是由提供数据集者爬取动漫中的图片，并使用动漫面孔检测算法，对于脸部进行打框标定，截取所得。具体的方式就如同PPT中右下角的方式一样。**(翻页)**

## 数据预处理

由于这个数据集是公开数据集，数据集的提供者已经做好了数据清洗工作。我主要介绍数据预处理工作。**(翻页)**

首先对于此图像数据集而言，由于数据量较大，共71314张图片，且尺寸为96 * 96，神经网络训练难度较大，因此，将图像尺寸缩放为64 * 64，减少训练所需要的时间。

其次是进行了图像标准化。标准化处理后的图像，大小与通道数目与原图像保持一致。图像中的像素值经过标准化之后的分布没有改变，变的只是其值大小。以下为标准化前后训练资料的对比。(上方为标准化前，下方为标准化后)。在进行图像标准化处理后，可以明显观察到进行标准化处理后，图像仍保留着动漫头像的特征，只不过是对比度改变了，像素值被调整到[-1,1]，这更有利于运算求梯度等操作。

此外我做了图像增广操作，经过对于动漫头像原始数据集的观察之后，发现原有图像数据集头像位置较为合适，无需进行局部放大或者缩小，因此并未选择使用随机裁剪的处理方法；又由于图像上下翻转对于生成动漫头像的意义不大，我想生成的图片也是脸朝上的，因此我只只采用了随机头像左右反转与图像亮度调整的数据增广方法。下图中可明显观察到第1张的亮度增加，后3张的亮度降低，并且第4张的头像进行了左右翻转。**(翻页)**

## GAN的简介

在熟悉数据之后，就迎来了重点的部分，使用GAN生成对抗网络来生成动漫图片。

生成对抗网络是非监督式学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。

下面这段话我就不读了，我用自己的理解做一下介绍。GAN叫做生成对抗网络，其实理解了 生成 对抗 网络 这三个词就能很好的解释GAN。**(翻页)**首先来说最简单的，N network。GAN它是深度学习之中的一种方法，他解决问题的核心思想和深度学习是一样的，都用到了神经网络模型。**(翻页)**

## N Network

拿1 + 1 = 2为例，以往我们要解决的问题，知道了输入1， 函数为 +，我们要得到输出2。   而机器学习的核心思想就是，已知我们的输入为1，输出为2，我们要寻找一个函数，这个函数的性质使得在输入为两个1的情况下，把这两个一放进函数，我们得到了输出二。  深度学习无非就是这个寻找的函数F(x),是通过神经网络的方法拟合的。**(翻页)**

## G 生成问题

接下来是G 生成问题，我们要有生成问题呢，处理生成问题的方法一般的分类回归问题不太一样的。**(翻页)**

接下来举一个例子。这是github上的一个开源项目，这个项目是从糖豆人游戏视频中，截取一系列的游戏画面，给定连续几帧的游戏画面，需要预测出下一帧的游戏画面。那由于可以一直录制这样的游戏画面，那么给定一张图片，放入这个模型中，它就会输出下一秒会产生的图片。

在开始时，作者在把它当作基本的分类问题处理,得到了特别有意思的现象，会发现这个糖豆人走着走着自己就裂开了，为什么会产生这样的原因呢，应为对于我们已有的训练资料而言，比如在这个转角停住不动，在下一帧，在训练资料中，有的糖豆人会左转，有的会右转，但是这样的资料都是正确的资料。那么你的模型学到的是又要往左转，又要往右转。向左是对的，向右也是对的，但是同时向左向右确实不对的。所以不能简单的把它当作分类、回归问题来看待。

在传统的回归分类问题之中，比如房价预测，给定一个x值，比如一个向量，它包含了房屋面积、地理位置等这个房子的特征向量，我们把它输入到神经网络之中，得到一个输出值y，就是这个房子的房价预测值。但是对于生成问题而言，此时我们需要输出是一个分布，这样的话，就需要我们的输入是一种分布。要把这个神经网络当作一个生成器来使用。**(翻页)**

## A 对抗性

介绍完GAN的G，我介绍以下GAN的A，也就是对抗性。

GAN主要分为两个神经网络一个是生成器，一个是辨别器。

对于生成器而言，他的输入是一个简单分布之中随机取样得到的向量，将这些向量送进生成器的神经网络，得到一个高维的向量；比如 我们的输入是1 * 10的向量，得到一个3 * 64 * 64的向量，其实生成器就是将一个简单向量变成了一张图片。**(翻页)**

而辨别器的任务是对于输入的图片进行打分，如果辨别器认为这张图片来自于真实的数据集，就打高分，如果认为这张图片是由生成器生成的，就打低分。辨别器也是神经网络。由于输入进入辨别器的是一张图片，我们可以使用传统一点的模型cnn，新一点的模型transofomer等，他们在处理图片方面上比较有优势。**(翻页)**

一开始的生成器，它的神经元参数完全是随机的，他不知道怎么去画一个动画人物，比如他画出来的全部都是噪音。而对于辨别器而言，它的学习目标就是分别由生成器产生出来的图片与真实图片之中的不同。对于辨别器而言，这就是一个非常简单的分类任务，就比如第一代的鉴别器学到了动漫人物都需要有眼睛。判断是否是真实任务需不需要眼睛是标准。那生成器为了骗过辨别器，得到高分，就开始进化，生成出来更像真实图片。那第二代的辨别器开始辨认是否有头发和嘴巴。第三代的为了骗过辨别器，又开始进化，同理，辨别器性能也跟着进化，对抗的含义。**(翻页)**



## 算法原理

接下来讲一下GAN的训练过程中的原理。

第一步，固定生成器，训练辨别器。随机选取一些向量，把这些向量丢到生成器之中，产生一些图片，一开始十分不像。同时取训练集之中的真实图片。就让辨别器对于真实图片与生成器产生的图片打分。分辨真正的图片与生成的图片间的区别。这就是一个分类问题，标签为真正的图片为1，生成器产生的为0，训练辨别器一个二分类分类器就好了。在此过程中，辨别器D学习到了：给从训练集中的真实图片高分 给由生成器G生成的图片低分**(翻页)**

第二步，固定辨别器，训练生成器，生成器的目标是让它产生的这张图片，在辨别器中的打分越高越好。在此过程中，生成器G学习到了：生成的图片欺骗辨别器D，获得辨别器D的高分。**(翻页)**

我们的训练过程要固定一个，训练另一个。训练一阵子生成器，训练一阵子辨别器。这就是”对抗“的本质。以上两步骤在GAN对抗生成网络中不断循环，理想情况下，可以获得性能较好的生成器G与辨别器D。在此时而再次选取一些服从简单分布(例如高斯分布)的向量，把这些向量输入训练结果较好的生成器G之中，便可以获得生成的图片。生成器G即为完成生成任务的模型。**(翻页)**



## 回到我的实验中

介绍完GAN，继续回到我的实验中。生成的图片它的前身就是右边这张图，每一行都是一个高维向量，它在通过生成器G之后，就转变成了一张图片。**(翻页)**

## 可视化

下面介绍训练过程的可视化过程。可以发现在训练不足时，动漫头像并不逼真，且并没有产生“分化”的效果。以第一轮训练结果为例，大部分头像均为紫红色，生成的头像之间较为相似。而随着训练轮数增多，头像之间开始出现分化的效果，并且动漫头像逐渐提高。**(翻页)**

## 模型评估

关于模型评估，由于生成任务的评估不想回归分类任务，有明确的评价指标，比如分类任务有准确率 查全率之类的。这里采用两种方法评估。首先就是主管观察，发现生成的图片起码看起来还像一个人脸，有眼睛鼻子嘴巴之类的。

另一个是采用FID指标，它说白了就是把产生的样本和真实数据集，放到另一个分类器里计算两类样本之间的差距。

我的介绍到此结束，谢谢大家。




