# GAN

大家好，我是胡才郁，今天我给大家介绍的主题是GAN，对抗生成网络。

我的介绍将分为4个部分，首先来介绍GAN的应用。那么GAN能用来做什么呢？我们生活中很多有趣的事情是关于GAN的，比如说，这个PPT封面图，就是用GAN的一个变种Cycle GAN产生的，把一匹变成普通的棕色的马变成斑马，再比如说用另一个变种Conditional GAN，给定蒙娜丽莎静态的图片，让蒙娜丽莎的嘴巴动起来。并且GAN也可以生成由人眼都无法辨认出来的人脸图片，比如说这两列结果，大家能看出来哪一列是真实的图片，哪一列是由GAN生成出来的不存在的人脸吗？其实这两列都是由Progressive GAN生成出来的。我们会发现GAN的技术真的很厉害，在捏脸这方面已经超越了人类。再比如说这两个人，大家如果对于深度学期领域有所了解的话，应该会认识他们两个，杨力坤和吴恩达，都是深度学习领域的大牛。用Style GAN生成出来两个人大佬是小孩子时的照片。

GAN绝对是当前AI领域非常热门的研究方向，在18年Github上有一个仓库，这个仓库名字叫做The GAN Zoo，整理了各种GAN的变体以及关联到这个变体GAN对应的论文，虽然这个仓库目前已经停止维护了，但是这个仓库整理出来的信息十分有价值。从事GAN方向的研究人员，他们每发明一种GAN时，都会用一个英文字母放到GAN的模型，给这个模型起名字，就比如说A-GAN，B-GAN。但是英文字母是有限的，不久26个字母全部用完了，看红框框住的这些，光是名字叫做SGAN的不同的模型就有好几个。

## GAN的简介

下一部分我来讲GAN的简介，什么是GAN呢？维基百科上的解释是这样的。

生成对抗网络（英语：**G**enerative **A**dversarial **N**etwork，简称GAN）是非监督式学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。

具体的这段话我就不读了，如果大家是第一次接触GAN这个模型的话，如果大家看这个定义的话很难理解这个GAN究竟是什么。那我用自己的理解做一下介绍。GAN叫做对抗生成网络，其实理解了 对抗 生成 网络 这三个词就能很好的解释GAN。首先来说最简单的N network。GAN它是深度学习之中的一种方法，他解决问题的核心思想和深度学习是一样的，都用到了神经网络模型。关于神经网络，之前的同学也介绍过了，我这边就简单的提一下。

拿1 + 1 = 2为例，以往我们要解决的问题，知道了输入1， 函数为 +，我们要得到输出2。   而深度学习的核心思想就是，已知我们的输入为1，输出为2，我们要寻找一个函数，这个函数的性质使得在输入为两个1的情况下，把这两个一放进函数，我们得到了输出二。  深度学习无非就是这个寻找的函数F(x),是通过神经网络的方法拟合的。





接下来我们来讨论生成问题

## G 生成问题

首先，为什么我们要有生成问题呢，处理生成问题的方法一般的分类回归问题不太一样的。

接下来举一个例子。这是github上的一个开源项目，这个项目是从糖豆人游戏视频中，截取一系列的游戏画面，给定连续几帧的游戏画面，需要预测出下一帧的游戏画面。那由于可以一直录制这样的游戏画面，那么给定一张图片，放入这个模型中，它就会输出下一秒会产生的图片。

在开始时，作者在把它当作基本的分类问题处理的时候会得到特别有意思的现象，会发现这个糖豆人走着走着自己就裂开了，为什么会产生这样的原因呢，应为对于我们已有的训练资料而言，比如在这个转角停住不动，在下一帧，在训练资料中，有的糖豆人会左转，有的会右转，但是这样的资料都是正确的资料。那么你的模型学到的是又要往左转，又要往右转。向左是对的，向右也是对的，但是同时向左向右确实不对的。所以不能简单的把它当作分类、回归问题来看待。

在传统的回归分类问题之中，比如房价预测，给定一个x值，比如一个向量，它包含了房屋面积、地理位置等这个房子的一个feature向量，我们把它输入到神经网络之中，得到一个输出值y，就是这个房子的房价预测值。

但是对于生成问题而言，此时我们需要输出是一个分布，这样的话，就需要我们的输入是一种分布。要把这个神经网络当作一个生成器来使用。举个例子，糖豆人在遇到岔路口时50%的几率向左，50%几率向右，与之前回归分类问题不同的地方在于，会加入一个z，不只是像房价预测一样，接受一个x，这个x只是一个确定的值。而是要将x与z结合起来，至于这个怎么结合。比如可以直接向量相加。这个z一定是一个足够简单的分布之中随机取出来的。例如均匀分布，高斯分布。由于此处的z不同，你的输入是一个分布，所以你得到的y值不只是单一的一个输出，而是一个分布，这就是解决生成问题的方法。

## A 对抗性

介绍了GAN中的G，生成的含义，接下来讲GAN中的A，对抗。

关于这个对抗意义的介绍，最知名的就是警察和小偷的故事，故事是这样的

假如一个城市有很多的小偷，小偷为了生存下去，就提升自己的反侦察能力

而警察为了能更好的抓小偷，就提升自己的破案能力，这有点像我们高中生物学过的共同进化的例子。



到了最后，警察和小偷的对抗之中都变得越来越强，最终我们得到了最强的小偷和最强的警察。



对于生成器而言，他的输入是一个简单分布之中随机取样得到的向量，将这些向量送进生成器的神经网络，得到一个高维的向量；比如 我们的输入是1 * 10的向量，得到一个3 * 64 * 64的向量，那大家听到这个维度一定很熟悉，就是一张大小为64 * 64的图像。

而辨别器的任务是对于输入的图片进行打分，如果辨别器认为这张图片来自于真实的数据集，就打高分，如果认为这张图片是由生成器生成的，就打低分。辨别器也是神经网络。由于输入进入辨别器的是一张图片，我们可以使用传统一点的模型cnn，新一点的模型transofomer等，他们在处理图片方面上比较有优势。

一开始的生成器，它的神经元参数完全是随机的，他不知道怎么去画一个动画人物，比如他画出来的全部都是噪音。而对于辨别器而言，它的学习目标就是分别由生成器产生出来的图片与真实图片之中的不同。对于辨别器而言，这就是一个非常简单的分类任务，就比如第一代的鉴别器学到了动漫人物都需要有眼睛。判断是否是真实任务需不需要眼睛是标准。那生成器为了骗过辨别器，得到高分，就开始进化，生成出来更像真实图片。那第二代的辨别器开始辨认是否有头发和嘴巴。第三代的为了骗过辨别器，又开始进化，同理，辨别器性能页跟着进化，对抗的含义。





接下来讲一下GAN的训练过程中的原理。

第一步，固定生成器，训练辨别器。随机选取一些向量，把这些向量丢到生成器之中，产生一些图片，一开始十分不像。同时取训练集之中的真实图片。就让辨别器对于真实图片与生成器产生的图片打分。分辨真正的图片与生成的图片间的区别。这就是一个分类问题，标签为真正的图片为1，生成器产生的为0，训练辨别器一个二分类分类器就好了。在此过程中，辨别器D学习到了：给从训练集中的真实图片高分 给由生成器G生成的图片低分

第二步，固定辨别器，训练生成器，生成器的目标是让它产生的这张图片，在辨别器中的打分越高越好。在此过程中，生成器G学习到了：生成的图片欺骗辨别器D，获得辨别器D的高分

可以把生成器与辨别器的组合可以看作一个巨大的network，是由两部分构成的，这个分界线为某一神经元，它的输出就是一张图片展开成向量。在它之前是生成器，在它之后是辨别器。对于整个神经网络而言，它吃一个向量作为输入，输出是一个分数，希望调整这个神经网络，让得到的分数越高越好，但是我们不会在第二步的时候不会去动后边几层的输出，只会去调整在这条分解线之前的参数。为什么不调后边几层呢，假设要调最后几层，那我直接把最后一层神经元的bias变成一百万，无论你输入怎样的向量，我的打分都会特别高，这样做是没有意义的。因此，我们的训练过陈要固定一个，训练另一个。训练一阵子生成器，训练一阵子辨别器。这就是”对抗“的本质。

接下来我们从代码的角度讲一下。
